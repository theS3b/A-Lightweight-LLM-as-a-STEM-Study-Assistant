{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b48640-cb04-45cb-8330-5ea570eefd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, json, torch, logging, os\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor import configure_logger, LoggerConfig\n",
    "\n",
    "from mmlu_eval import evaluate_mmlu, mmlu_harness_hf, display_metric\n",
    "\n",
    "configure_logger(LoggerConfig(\n",
    "    disabled=True,\n",
    "    clear_loggers=True,\n",
    "    console_log_level=None,\n",
    "    log_file=None,\n",
    "    log_file_level=None\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5feb48ee-bbd8-4ade-94a2-9314a411d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_prefix = \"TheS3b/Qwen3-0.6B-SmoothQuant-W8A8-calib\"  # base name for HF pushes\n",
    "model_repo = \"brygotti/MNLP_M2_mcqa_model\"\n",
    "BITS         = 8\n",
    "BLOCK_SIZE   = 64\n",
    "prompt_sizes = [20, 200, 2000]\n",
    "MAX_SEQUENCE_LENGTH = 2048\n",
    "\n",
    "logging.disable(logging.INFO)\n",
    "os.environ[\"EXLLAMA_KERNELS_AVAILABLE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc39c42-b6cf-4932-a28e-ad4bd5bd54bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "── SmoothQuant W8A8 with 20 calibration prompts ──\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 24.41it/s]\n",
      "Preparing intermediates cache: 100%|██████████| 20/20 [00:00<00:00, 2246.73it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 293.26it/s]\n",
      "(1/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 435.39it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.00it/s]\n",
      "(2/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 599.08it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 343.06it/s]\n",
      "(3/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 568.46it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 342.44it/s]\n",
      "(4/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 628.49it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 343.47it/s]\n",
      "(5/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 634.09it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 349.04it/s]\n",
      "(6/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 629.00it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.95it/s]\n",
      "(7/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 570.42it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.91it/s]\n",
      "(8/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 606.52it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 342.87it/s]\n",
      "(9/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 631.03it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 350.01it/s]\n",
      "(10/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 495.82it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 294.37it/s]\n",
      "(11/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 594.78it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.30it/s]\n",
      "(12/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 567.63it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.96it/s]\n",
      "(13/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 556.81it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 345.09it/s]\n",
      "(14/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 583.17it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 348.82it/s]\n",
      "(15/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 614.29it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 343.39it/s]\n",
      "(16/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 632.76it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 347.51it/s]\n",
      "(17/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 641.09it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 342.91it/s]\n",
      "(18/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 639.53it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 346.90it/s]\n",
      "(19/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 635.09it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 345.22it/s]\n",
      "(20/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 641.17it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 349.26it/s]\n",
      "(21/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 634.99it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 348.53it/s]\n",
      "(22/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 612.73it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 347.50it/s]\n",
      "(23/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 637.66it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 348.70it/s]\n",
      "(24/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 588.05it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 347.96it/s]\n",
      "(25/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 626.41it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 344.88it/s]\n",
      "(26/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 630.44it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 346.25it/s]\n",
      "(27/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 632.28it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 348.58it/s]\n",
      "(28/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 600.53it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 20/20 [00:00<00:00, 1255.40it/s]\n",
      "(29/29): Propagating: 100%|██████████| 20/20 [00:00<00:00, 1345.67it/s]\n",
      "Evaluating:  11%|█▏        | 221/1962 [02:42<21:10,  1.37it/s]"
     ]
    }
   ],
   "source": [
    "# Tokenizer once\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_repo, trust_remote_code=True)\n",
    "\n",
    "# Re-use the calibration set you already filtered\n",
    "calibration_data = load_dataset(\"TheS3b/unified-dataset-filtered-430K\")\n",
    "def is_valid_prompt(example, min_len=64, max_len=256, thresh=0.5):\n",
    "    tokens = tokenizer(example[\"prompt\"], return_tensors=\"pt\")[\"input_ids\"]\n",
    "    return min_len <= tokens.shape[1] <= max_len and (example[\"relevance1\"] + example[\"relevance2\"]) * 0.5 > thresh\n",
    "filtered_calibration_set = calibration_data.filter(\n",
    "    lambda ex: is_valid_prompt(ex), batched=False\n",
    ").shuffle(seed=42)[\"train\"]\n",
    "\n",
    "# Tokenisation helper for llm-compressor (expects tokenised samples)\n",
    "def tokenise(sample):\n",
    "    return tokenizer(\n",
    "        sample[\"prompt\"],\n",
    "        padding=False,\n",
    "        max_length=MAX_SEQUENCE_LENGTH,\n",
    "        truncation=True,\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "\n",
    "# Your evaluation set and helpers (unchanged)\n",
    "eval_ds = load_dataset(\"brygotti/NLP4Education_english_single_mcq_4_choices\")[\"test\"]\n",
    "\n",
    "for size in prompt_sizes:\n",
    "    print(f\"\\n── SmoothQuant W{BITS}A8 with {size} calibration prompts ──\\n\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Build tokenised calibration dataset\n",
    "    calib_ds = filtered_calibration_set.select(range(size)).map(\n",
    "        tokenise, remove_columns=filtered_calibration_set.column_names\n",
    "    )\n",
    "\n",
    "    # FP16 baseline model (no quantisation yet)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_repo,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"cuda\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    # Compression “recipe”: SmoothQuant first, *optional* GPTQ second\n",
    "    recipe = [\n",
    "        SmoothQuantModifier(\n",
    "            smoothing_strength=0.8,\n",
    "            ignore=[\"lm_head\"],\n",
    "            num_calibration_steps=size,\n",
    "            block_size=BLOCK_SIZE,\n",
    "        ),\n",
    "        GPTQModifier(\n",
    "            scheme=f\"W{BITS}A8\",\n",
    "            targets=\"Linear\",\n",
    "            ignore=[\"lm_head\"],\n",
    "            block_size=BLOCK_SIZE,\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    # One-shot quantisation pass\n",
    "    oneshot(\n",
    "        model=model,\n",
    "        dataset=calib_ds,\n",
    "        recipe=recipe,\n",
    "        max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "        num_calibration_samples=size,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    metrics = evaluate_mmlu(eval_ds, model, tokenizer, device, mmlu_harness_hf)\n",
    "    display_metric(f\"SmoothQuant W{BITS}A8 Size {size}\", metrics)\n",
    "    key = f\"SmoothQuant W{BITS}A8 calib{size}\"\n",
    "    all_metrics[key] = metrics\n",
    "\n",
    "    push_name = f\"{hub_prefix}{size}\"\n",
    "    tokenizer.push_to_hub(push_name)\n",
    "    model.push_to_hub(push_name)\n",
    "\n",
    "    with open(\"Results/smooth_quant_metrics_calibration.json\", \"w\") as f:\n",
    "        json.dump(all_metrics, f, indent=2)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb0cea-c2dc-420f-aed9-898fd605c3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc2536-715d-48b6-bd4d-0b68bf1c5540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnlp_compute",
   "language": "python",
   "name": "mnlp_compute"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
